{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8ef236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-30T15:48:48.611481Z",
     "start_time": "2021-10-30T15:48:22.008757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trento\n",
      "----------------------------------Training for  Trento ---------------------------------------------\n",
      "Train data shape =  torch.Size([819, 11, 11, 63])\n",
      "Train label shape =  torch.Size([1, 819])\n",
      "Test data shape =  torch.Size([29395, 11, 11, 63])\n",
      "Test label shape =  torch.Size([1, 29395])\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-30 08:48:22.934138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1564] Found device 0 with properties: \n",
      "pciBusID: 0035:03:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.50GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-10-30 08:48:22.934276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\n",
      "2021-10-30 08:48:22.934308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-10-30 08:48:22.934335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-30 08:48:22.934361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-30 08:48:22.934424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-30 08:48:22.934455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-10-30 08:48:22.934482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-10-30 08:48:22.936427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1706] Adding visible gpu devices: 0\n",
      "2021-10-30 08:48:22.936481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-30 08:48:22.936495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1111]      0 \n",
      "2021-10-30 08:48:22.936507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1124] 0:   N \n",
      "2021-10-30 08:48:22.938806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1250] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11663 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0035:03:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Train on 819 samples, validate on 29395 samples\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-30 08:48:24.379139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1564] Found device 0 with properties: \n",
      "pciBusID: 0035:03:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.50GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-10-30 08:48:24.379208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2\n",
      "2021-10-30 08:48:24.379229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-10-30 08:48:24.379245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-30 08:48:24.379262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-30 08:48:24.379322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-10-30 08:48:24.379361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-10-30 08:48:24.379389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-10-30 08:48:24.381340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1706] Adding visible gpu devices: 0\n",
      "2021-10-30 08:48:24.381391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-30 08:48:24.381404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1111]      0 \n",
      "2021-10-30 08:48:24.381415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1124] 0:   N \n",
      "2021-10-30 08:48:24.383121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1250] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11663 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0035:03:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "819/819 [==============================] - 4s 5ms/sample - loss: 1.4796 - accuracy: 0.3419 - val_loss: 1.1510 - val_accuracy: 0.8605\n",
      "Epoch 2/200\n",
      "819/819 [==============================] - 4s 5ms/sample - loss: 0.9144 - accuracy: 0.6825 - val_loss: 0.8291 - val_accuracy: 0.8097\n",
      "Epoch 3/200\n",
      "819/819 [==============================] - 4s 5ms/sample - loss: 0.5754 - accuracy: 0.8877 - val_loss: 0.4920 - val_accuracy: 0.8526\n",
      "Epoch 4/200\n",
      "819/819 [==============================] - 4s 5ms/sample - loss: 0.3399 - accuracy: 0.9121 - val_loss: 0.3124 - val_accuracy: 0.9137\n",
      "Epoch 5/200\n",
      "819/819 [==============================] - 4s 5ms/sample - loss: 0.2164 - accuracy: 0.9316 - val_loss: 0.3126 - val_accuracy: 0.8847\n",
      "Epoch 6/200\n",
      "819/819 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9170"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126664/3249559979.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvaldata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                                 callbacks = [ModelCheckpoint(datasetName+\"/best_model_HSIOnly.h5\", monitor='val_accuracy', verbose=0, save_best_only=True)])\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    432\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3632\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############ IMPORTS ####################\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import torch\n",
    "from operator import truediv\n",
    "import record\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers import Dense, Flatten, GRU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical as keras_to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "############# CONFIGS ##########################\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "datasetNames = [\"Trento\"]\n",
    "patchsize1 = 11\n",
    "patchsize2 = 11\n",
    "batchsize = 64\n",
    "EPOCH = 200\n",
    "LR = 0.001\n",
    "\n",
    "    \n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc*100, average_acc*100\n",
    "\n",
    "def get_model_compiled(feat_size,seq, Classes):\n",
    "    func = GRU\n",
    "    clf = Sequential()\n",
    "    clf.add(func(64, return_sequences=True, input_shape=(feat_size, seq)))\n",
    "    clf.add(func(64, return_sequences=True))\n",
    "    clf.add(Flatten())\n",
    "    clf.add(Dense(Classes, activation='softmax'))\n",
    "    clf.compile(loss=categorical_crossentropy, optimizer=Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False), metrics=['accuracy'])\n",
    "    return clf\n",
    "\n",
    "\n",
    "for datasetName in datasetNames:\n",
    "    print(datasetName)\n",
    "    HSIOnly = True\n",
    "    try:\n",
    "        os.makedirs(datasetName)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    for i in range(1):\n",
    "        print(\"----------------------------------Training for \",datasetName,\"---------------------------------------------\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(datasetName)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    # Train data\n",
    "    HSI = io.loadmat('./../'+datasetName+'11x11/HSI_Tr.mat')\n",
    "    TrainPatch = HSI['Data']\n",
    "    TrainPatch = TrainPatch.astype(np.float32)\n",
    "    NC = TrainPatch.shape[3] # NC is number of bands\n",
    "    \n",
    "    label = io.loadmat('./../'+datasetName+'11x11/TrLabel.mat')\n",
    "    TrLabel = label['Data']\n",
    "    \n",
    "    # Test data\n",
    "    HSI = io.loadmat('./../'+datasetName+'11x11/HSI_Te.mat')\n",
    "    TestPatch = HSI['Data']\n",
    "    TestPatch = TestPatch.astype(np.float32)\n",
    "    \n",
    "    label = io.loadmat('./../'+datasetName+'11x11/TeLabel.mat')\n",
    "    TsLabel = label['Data']\n",
    "\n",
    "    \n",
    "    TrainPatch1 = torch.from_numpy(TrainPatch)\n",
    "#         TrainPatch1 = TrainPatch1.permute(0,3,1,2)\n",
    "    TrainLabel1 = torch.from_numpy(TrLabel)-1\n",
    "    TrainLabel1 = TrainLabel1.long()\n",
    "    \n",
    "\n",
    "    TestPatch1 = torch.from_numpy(TestPatch)\n",
    "#         TestPatch1 = TestPatch1.permute(0,3,1,2)\n",
    "    TestLabel1 = torch.from_numpy(TsLabel)-1\n",
    "    TestLabel1 = TestLabel1.long()\n",
    "\n",
    "    Classes = len(np.unique(TrainLabel1))\n",
    "    print(\"Train data shape = \", TrainPatch1.shape)\n",
    "    print(\"Train label shape = \", TrainLabel1.shape)\n",
    "    print(\"Test data shape = \", TestPatch1.shape)\n",
    "    print(\"Test label shape = \", TestLabel1.shape)\n",
    "    \n",
    "    KAPPA = []\n",
    "    OA = []\n",
    "    AA = []\n",
    "    ELEMENT_ACC = np.zeros((3, Classes))\n",
    "\n",
    "    tf.compat.v1.keras.backend.clear_session()\n",
    "    config = tf.compat.v1.ConfigProto( device_count = {'GPU': 2} ) \n",
    "    sess = tf.compat.v1.Session(config=config) \n",
    "    tf.compat.v1.keras.backend.set_session(sess)\n",
    "    g = tf.Graph()\n",
    "    with g.as_default():\n",
    "        for iter in range(3):\n",
    "            n_bands, sequences = TrainPatch1.reshape(TrainPatch1.size(0),TrainPatch1.size(1),-1).cpu().detach().numpy().shape[1:]\n",
    "            clf = get_model_compiled(n_bands, sequences, Classes)\n",
    "            valdata = (TestPatch1.reshape(TestPatch1.shape[0],TestPatch1.shape[1],-1).cpu().detach().numpy(), keras_to_categorical(TestLabel1.reshape(-1).cpu().detach().numpy(),Classes))\n",
    "            clf.fit(TrainPatch1.reshape(TrainPatch1.shape[0],TrainPatch1.shape[1],-1).cpu().detach().numpy(), keras_to_categorical(TrainLabel1.reshape(-1).cpu().detach().numpy(),Classes),\n",
    "                                batch_size=batchsize,\n",
    "                                epochs=EPOCH,\n",
    "                                verbose=True,\n",
    "                                validation_data=valdata,\n",
    "                                callbacks = [ModelCheckpoint(datasetName+\"/best_model_HSIOnly.h5\", monitor='val_accuracy', verbose=0, save_best_only=True)])\n",
    "\n",
    "\n",
    "\n",
    "            clf = load_model(datasetName+\"/best_model_HSIOnly.h5\")\n",
    "            pred_y = np.argmax(clf.predict(TestPatch1.reshape(TestPatch1.shape[0],TestPatch1.shape[1],-1).cpu().detach().numpy()), axis=1)\n",
    "\n",
    "            y_test = TestLabel1.reshape(-1).cpu().detach().numpy()\n",
    "            oa = accuracy_score(y_test, pred_y)*100\n",
    "            confusion = confusion_matrix(y_test, pred_y)\n",
    "            each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "            kappa = cohen_kappa_score(y_test, pred_y)*100\n",
    "            KAPPA.append(kappa)\n",
    "            OA.append(oa)\n",
    "            AA.append(aa)\n",
    "            ELEMENT_ACC[iter, :] = each_acc\n",
    "    print(\"--------\" + datasetName + \" Training Finished-----------\")\n",
    "    record.record_output(OA, AA, KAPPA, ELEMENT_ACC,'./' + datasetName +'/GRU_Report_' + datasetName +'.txt')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
