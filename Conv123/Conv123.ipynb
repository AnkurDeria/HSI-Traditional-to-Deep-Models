{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2006c3",
   "metadata": {},
   "source": [
    "# Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b897231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T13:55:52.418034Z",
     "start_time": "2021-10-29T13:55:25.572996Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Training for  Trento ---------------------------------------------\n",
      "Train data shape =  torch.Size([819, 11, 11, 63])\n",
      "Train label shape =  torch.Size([1, 819])\n",
      "Test data shape =  torch.Size([29395, 11, 11, 63])\n",
      "Test label shape =  torch.Size([1, 29395])\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 98, 20)            30260     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 19, 20)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 380)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               38100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 69,366\n",
      "Trainable params: 69,166\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4/4 [==============================] - 1s 162ms/step - loss: 1.4707 - accuracy: 0.4212 - val_loss: 1.5880 - val_accuracy: 0.3955\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 1s 139ms/step - loss: 0.5849 - accuracy: 0.9170 - val_loss: 2.1905 - val_accuracy: 0.4252\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 1s 134ms/step - loss: 0.4043 - accuracy: 0.9096 - val_loss: 2.8617 - val_accuracy: 0.4410\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 107ms/step - loss: 0.3230 - accuracy: 0.9267 - val_loss: 3.2829 - val_accuracy: 0.4401\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.2539 - accuracy: 0.9475 - val_loss: 3.4747 - val_accuracy: 0.4391\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.2082 - accuracy: 0.9683 - val_loss: 3.5851 - val_accuracy: 0.4444\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.1653 - accuracy: 0.9744 - val_loss: 3.5831 - val_accuracy: 0.4485\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.1403 - accuracy: 0.9780 - val_loss: 3.4769 - val_accuracy: 0.4514\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.1177 - accuracy: 0.9780 - val_loss: 3.3398 - val_accuracy: 0.4531\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 109ms/step - loss: 0.1010 - accuracy: 0.9792 - val_loss: 3.1425 - val_accuracy: 0.4514\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0949 - accuracy: 0.9841 - val_loss: 2.8869 - val_accuracy: 0.4541\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0831 - accuracy: 0.9792 - val_loss: 2.5791 - val_accuracy: 0.4543\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 1s 127ms/step - loss: 0.0865 - accuracy: 0.9866 - val_loss: 2.4006 - val_accuracy: 0.4546\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0653 - accuracy: 0.9841 - val_loss: 2.2386 - val_accuracy: 0.4549\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 1s 131ms/step - loss: 0.0618 - accuracy: 0.9829 - val_loss: 1.9983 - val_accuracy: 0.4549\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0557 - accuracy: 0.9976 - val_loss: 1.8998 - val_accuracy: 0.4558\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 1s 154ms/step - loss: 0.0594 - accuracy: 0.9866 - val_loss: 1.7737 - val_accuracy: 0.4613\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.0508 - accuracy: 0.9951 - val_loss: 1.8192 - val_accuracy: 0.4609\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0461 - accuracy: 1.0000 - val_loss: 1.8932 - val_accuracy: 0.4678\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0369 - accuracy: 0.9988 - val_loss: 1.7338 - val_accuracy: 0.4773\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 1s 137ms/step - loss: 0.0319 - accuracy: 0.9988 - val_loss: 1.6243 - val_accuracy: 0.4791\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 1s 129ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 1.4352 - val_accuracy: 0.4816\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 120ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 1.3410 - val_accuracy: 0.5057\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 1s 136ms/step - loss: 0.0281 - accuracy: 0.9963 - val_loss: 1.2463 - val_accuracy: 0.5140\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 1s 144ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.1285 - val_accuracy: 0.5207\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.1090 - val_accuracy: 0.5306\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 123ms/step - loss: 0.0250 - accuracy: 0.9951 - val_loss: 1.0344 - val_accuracy: 0.5689\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.0736 - val_accuracy: 0.5359\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.0289 - val_accuracy: 0.5522\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 125ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.8503 - val_accuracy: 0.6571\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 1s 128ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.7663 - val_accuracy: 0.6995\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.7402 - val_accuracy: 0.7097\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 1s 130ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.6931 - val_accuracy: 0.7432\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5930 - val_accuracy: 0.7853\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.8651\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.8229\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.8107\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 1s 147ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5592 - val_accuracy: 0.7956\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 1s 150ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.7818\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 116ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.8480\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 118ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.8505\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.8311\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 122ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.8910\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 1s 126ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9127\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 117ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9157\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9224\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.9208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 108ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.3218 - val_accuracy: 0.9080\n",
      "Epoch 49/200\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_160806/4245517695.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    108\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvaldata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                             callbacks = [ModelCheckpoint(datasetName+\"/best_model_HSIOnly_Conv1D.h5\", monitor='val_accuracy', verbose=0, save_best_only=True)])\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############ IMPORTS ####################\n",
    "import sys\n",
    "sys.path.append('./../')\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import torch\n",
    "from operator import truediv\n",
    "import record\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers import Activation, BatchNormalization, Conv1D, Dense, Flatten, MaxPooling1D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical as keras_to_categorical\n",
    "\n",
    "############# CONFIGS ##########################\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "datasetNames = [\"Trento\"]\n",
    "patchsize1 = 11\n",
    "patchsize2 = 11\n",
    "batchsize = 256\n",
    "EPOCH = 200\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc*100, average_acc*100\n",
    "\n",
    "def get_model_compiled(bands, num_class):\n",
    "    clf = Sequential()\n",
    "    clf.add(Conv1D(20, (24), activation='relu', input_shape=(patchsize1*patchsize2,bands)))\n",
    "    clf.add(MaxPooling1D(pool_size=5))\n",
    "    clf.add(Flatten())\n",
    "    clf.add(Dense(100))\n",
    "    clf.add(BatchNormalization())\n",
    "    clf.add(Activation('relu'))\n",
    "    clf.add(Dense(num_class, activation='softmax'))\n",
    "    clf.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "    return clf\n",
    "        \n",
    "for datasetName in datasetNames:\n",
    "    print(\"----------------------------------Training for \",datasetName,\"---------------------------------------------\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(datasetName)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    # Train data\n",
    "    HSI = io.loadmat('./../'+datasetName+'11x11/HSI_Tr.mat')\n",
    "    TrainPatch = HSI['Data']\n",
    "    TrainPatch = TrainPatch.astype(np.float32)\n",
    "    NC = TrainPatch.shape[3] # NC is number of bands\n",
    "    \n",
    "    label = io.loadmat('./../'+datasetName+'11x11/TrLabel.mat')\n",
    "    TrLabel = label['Data']\n",
    "    \n",
    "    # Test data\n",
    "    HSI = io.loadmat('./../'+datasetName+'11x11/HSI_Te.mat')\n",
    "    TestPatch = HSI['Data']\n",
    "    TestPatch = TestPatch.astype(np.float32)\n",
    "    \n",
    "    label = io.loadmat('./../'+datasetName+'11x11/TeLabel.mat')\n",
    "    TsLabel = label['Data']\n",
    "\n",
    "    \n",
    "    TrainPatch1 = torch.from_numpy(TrainPatch)\n",
    "#         TrainPatch1 = TrainPatch1.permute(0,3,1,2)\n",
    "    TrainLabel1 = torch.from_numpy(TrLabel)-1\n",
    "    TrainLabel1 = TrainLabel1.long()\n",
    "    \n",
    "\n",
    "    TestPatch1 = torch.from_numpy(TestPatch)\n",
    "#         TestPatch1 = TestPatch1.permute(0,3,1,2)\n",
    "    TestLabel1 = torch.from_numpy(TsLabel)-1\n",
    "    TestLabel1 = TestLabel1.long()\n",
    "\n",
    "    Classes = len(np.unique(TrainLabel1))\n",
    "    print(\"Train data shape = \", TrainPatch1.shape)\n",
    "    print(\"Train label shape = \", TrainLabel1.shape)\n",
    "    print(\"Test data shape = \", TestPatch1.shape)\n",
    "    print(\"Test label shape = \", TestLabel1.shape)\n",
    "    \n",
    "    KAPPA = []\n",
    "    OA = []\n",
    "    AA = []\n",
    "    ELEMENT_ACC = np.zeros((3, Classes))\n",
    "    \n",
    "    for iter in range(3):\n",
    "        clf = get_model_compiled(NC, Classes)\n",
    "        clf.summary()\n",
    "        valdata = (TestPatch1.reshape(TestPatch1.shape[0],TestPatch1.shape[1]*TestPatch1.shape[2],TestPatch1.shape[3]).cpu().detach().numpy(), keras_to_categorical(TestLabel1.reshape(-1).cpu().detach().numpy(),Classes))\n",
    "        clf.fit(TrainPatch1.reshape(TrainPatch1.shape[0],TrainPatch1.shape[1]*TrainPatch1.shape[2],TrainPatch1.shape[3]).cpu().detach().numpy(), keras_to_categorical(TrainLabel1.reshape(-1).cpu().detach().numpy(),Classes),\n",
    "                            batch_size=batchsize,\n",
    "                            epochs=EPOCH,\n",
    "                            verbose=True,\n",
    "                            validation_data=valdata,\n",
    "                            callbacks = [ModelCheckpoint(datasetName+\"/best_model_HSIOnly_Conv1D.h5\", monitor='val_accuracy', verbose=0, save_best_only=True)])\n",
    "\n",
    "\n",
    "\n",
    "        clf = load_model(datasetName+\"/best_model_HSIOnly_Conv1D.h5\")\n",
    "        pred_y = np.argmax(clf.predict(TestPatch1.reshape(TestPatch1.shape[0],TestPatch1.shape[1]*TestPatch1.shape[2],TestPatch1.shape[3]).cpu().detach().numpy()), axis=1)\n",
    "\n",
    "        y_test = TestLabel1.reshape(-1).cpu().detach().numpy()\n",
    "        oa = accuracy_score(y_test, pred_y)*100\n",
    "        confusion = confusion_matrix(y_test, pred_y)\n",
    "        each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "        kappa = cohen_kappa_score(y_test, pred_y)*100\n",
    "        KAPPA.append(kappa)\n",
    "        OA.append(oa)\n",
    "        AA.append(aa)\n",
    "        ELEMENT_ACC[iter, :] = each_acc\n",
    "\n",
    "    print(\"--------\" + datasetName + \" Training Finished-----------\")\n",
    "    record.record_output(OA, AA, KAPPA, ELEMENT_ACC,'./' + datasetName +'/Conv1D_Report_' + datasetName +'.txt')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfca634",
   "metadata": {},
   "source": [
    "# Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd68dd92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-29T14:07:28.111451Z",
     "start_time": "2021-10-29T14:07:10.010173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Training for  Trento ---------------------------------------------\n",
      "Train data shape =  torch.Size([819, 11, 11, 63])\n",
      "Train label shape =  torch.Size([1, 819])\n",
      "Test data shape =  torch.Size([29395, 11, 11, 63])\n",
      "Test label shape =  torch.Size([1, 29395])\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 50)          78800     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 100)         125100    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 100)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 214,606\n",
      "Trainable params: 214,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13/13 [==============================] - 5s 353ms/step - loss: 3.1773 - accuracy: 0.4066 - val_loss: 2.6671 - val_accuracy: 0.4896\n",
      "Epoch 2/200\n",
      "13/13 [==============================] - 4s 329ms/step - loss: 2.3752 - accuracy: 0.5922 - val_loss: 2.2364 - val_accuracy: 0.5516\n",
      "Epoch 3/200\n",
      "13/13 [==============================] - 4s 334ms/step - loss: 2.0020 - accuracy: 0.6654 - val_loss: 1.8904 - val_accuracy: 0.7294\n",
      "Epoch 4/200\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 1.7320 - accuracy: 0.7812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_160806/3308098394.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvaldata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                             callbacks = [ModelCheckpoint(datasetName+\"/best_model_HSIOnly_Conv2D.h5\", monitor='val_accuracy', verbose=0, save_best_only=True)])\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1055\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m                **kwargs):\n\u001b[1;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1006\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/purb37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############ IMPORTS ####################\n",
    "import sys\n",
    "sys.path.append('./../')\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import torch\n",
    "from operator import truediv\n",
    "import record\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical as keras_to_categorical\n",
    "\n",
    "############# CONFIGS ##########################\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "datasetNames = [\"Trento\"]\n",
    "batchsize = 256\n",
    "EPOCH = 200\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc*100, average_acc*100\n",
    "\n",
    "def get_model_compiled(shapeinput, num_class, w_decay=0):\n",
    "    clf = Sequential()\n",
    "    clf.add(Conv2D(50, kernel_size=(5, 5), input_shape=shapeinput))\n",
    "    clf.add(Activation('relu'))\n",
    "    clf.add(Conv2D(100, (5, 5)))\n",
    "    clf.add(Activation('relu'))\n",
    "    clf.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    clf.add(Flatten())\n",
    "    clf.add(Dense(100, kernel_regularizer=regularizers.l2(w_decay)))\n",
    "    clf.add(Activation('relu'))\n",
    "    clf.add(Dense(num_class, activation='softmax'))\n",
    "    clf.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['accuracy'])\n",
    "    return clf\n",
    "\n",
    "        \n",
    "for datasetName in datasetNames:\n",
    "    print(\"----------------------------------Training for \",datasetName,\"---------------------------------------------\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(datasetName)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    # Train data\n",
    "    HSI = io.loadmat('./../'+datasetName+'11x11/HSI_Tr.mat')\n",
    "    TrainPatch = HSI['Data']\n",
    "    TrainPatch = TrainPatch.astype(np.float32)\n",
    "    NC = TrainPatch.shape[3] # NC is number of bands\n",
    "    \n",
    "    label = io.loadmat('./../'+datasetName+'11x11/TrLabel.mat')\n",
    "    TrLabel = label['Data']\n",
    "    \n",
    "    # Test data\n",
    "    HSI = io.loadmat('./../'+datasetName+'11x11/HSI_Te.mat')\n",
    "    TestPatch = HSI['Data']\n",
    "    TestPatch = TestPatch.astype(np.float32)\n",
    "    \n",
    "    label = io.loadmat('./../'+datasetName+'11x11/TeLabel.mat')\n",
    "    TsLabel = label['Data']\n",
    "\n",
    "    \n",
    "    TrainPatch1 = torch.from_numpy(TrainPatch)\n",
    "#         TrainPatch1 = TrainPatch1.permute(0,3,1,2)\n",
    "    TrainLabel1 = torch.from_numpy(TrLabel)-1\n",
    "    TrainLabel1 = TrainLabel1.long()\n",
    "    \n",
    "\n",
    "    TestPatch1 = torch.from_numpy(TestPatch)\n",
    "#         TestPatch1 = TestPatch1.permute(0,3,1,2)\n",
    "    TestLabel1 = torch.from_numpy(TsLabel)-1\n",
    "    TestLabel1 = TestLabel1.long()\n",
    "\n",
    "    Classes = len(np.unique(TrainLabel1))\n",
    "    print(\"Train data shape = \", TrainPatch1.shape)\n",
    "    print(\"Train label shape = \", TrainLabel1.shape)\n",
    "    print(\"Test data shape = \", TestPatch1.shape)\n",
    "    print(\"Test label shape = \", TestLabel1.shape)\n",
    "    \n",
    "    KAPPA = []\n",
    "    OA = []\n",
    "    AA = []\n",
    "    ELEMENT_ACC = np.zeros((3, Classes))\n",
    "    \n",
    "    for iter in range(3):\n",
    "        inputshape = TrainPatch1.shape[1:]\n",
    "        clf = get_model_compiled(inputshape, Classes, w_decay = 0.02)\n",
    "        clf.summary()\n",
    "        valdata = (TestPatch1.cpu().detach().numpy(), keras_to_categorical(TestLabel1.reshape(-1).cpu().detach().numpy(),Classes))\n",
    "        clf.fit(TrainPatch1.cpu().detach().numpy(), keras_to_categorical(TrainLabel1.reshape(-1).cpu().detach().numpy(),Classes),\n",
    "                            batch_size=batchsize,\n",
    "                            epochs=EPOCH,\n",
    "                            verbose=True,\n",
    "                            validation_data=valdata,\n",
    "                            callbacks = [ModelCheckpoint(datasetName+\"/best_model_HSIOnly_Conv2D.h5\", monitor='val_accuracy', verbose=0, save_best_only=True)])\n",
    "\n",
    "\n",
    "\n",
    "        clf = load_model(datasetName+\"/best_model_HSIOnly_Conv2D.h5\")\n",
    "        pred_y = np.argmax(clf.predict(TestPatch1.cpu().detach().numpy()), axis=1)\n",
    "\n",
    "        y_test = TestLabel1.reshape(-1).cpu().detach().numpy()\n",
    "        oa = accuracy_score(y_test, pred_y)*100\n",
    "        confusion = confusion_matrix(y_test, pred_y)\n",
    "        each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "        kappa = cohen_kappa_score(y_test, pred_y)*100\n",
    "        KAPPA.append(kappa)\n",
    "        OA.append(oa)\n",
    "        AA.append(aa)\n",
    "        ELEMENT_ACC[iter, :] = each_acc\n",
    "\n",
    "    print(\"--------\" + datasetName + \" Training Finished-----------\")\n",
    "    record.record_output(OA, AA, KAPPA, ELEMENT_ACC,'./' + datasetName +'/Conv2D_Report_' + datasetName +'.txt')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df570dc5",
   "metadata": {},
   "source": [
    "# Conv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5bad8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-05T02:09:23.341537Z",
     "start_time": "2021-10-04T22:25:23.186928Z"
    }
   },
   "outputs": [],
   "source": [
    "############ IMPORTS ####################\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "import torch\n",
    "from operator import truediv\n",
    "import record\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.layers import Activation, BatchNormalization, Conv3D, Dense, Flatten, MaxPooling3D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.utils import to_categorical as keras_to_categorical\n",
    "\n",
    "\n",
    "############# CONFIGS ##########################\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "datasetNames = [\"Trento\"]\n",
    "batchsize = 256\n",
    "EPOCH = 200\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc*100, average_acc*100\n",
    "\n",
    "def get_model_compiled(shapeinput, num_class, w_decay=0, lr=1e-3):\n",
    "            clf = Sequential()\n",
    "            clf.add(Conv3D(32, kernel_size=(5, 5, 24), input_shape=shapeinput))\n",
    "            clf.add(BatchNormalization())\n",
    "            clf.add(Activation('relu'))\n",
    "            clf.add(Conv3D(64, (5, 5, 16)))\n",
    "            clf.add(BatchNormalization())\n",
    "            clf.add(Activation('relu'))\n",
    "            clf.add(MaxPooling3D(pool_size=(2, 2, 1)))\n",
    "            clf.add(Flatten())\n",
    "            clf.add(Dense(300, kernel_regularizer=regularizers.l2(w_decay)))\n",
    "            clf.add(BatchNormalization())\n",
    "            clf.add(Activation('relu'))\n",
    "            clf.add(Dense(num_class, activation='softmax'))\n",
    "            clf.compile(loss=categorical_crossentropy, optimizer=Adam(lr=lr), metrics=['accuracy'])\n",
    "            return clf\n",
    "        \n",
    "        \n",
    "for datasetName in datasetNames:\n",
    "    print(\"----------------------------------Training for \",datasetName,\"---------------------------------------------\")\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(datasetName)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    # Train data\n",
    "    HSI = io.loadmat('./../'+datasetName+'11x11/HSI_Tr.mat')\n",
    "    TrainPatch = HSI['Data']\n",
    "    TrainPatch = TrainPatch.astype(np.float32)\n",
    "    NC = TrainPatch.shape[3] # NC is number of bands\n",
    "    \n",
    "    label = io.loadmat('./../'+datasetName+'11x11/TrLabel.mat')\n",
    "    TrLabel = label['Data']\n",
    "    \n",
    "    # Test data\n",
    "    HSI = io.loadmat('./../'+datasetName+'11x11/HSI_Te.mat')\n",
    "    TestPatch = HSI['Data']\n",
    "    TestPatch = TestPatch.astype(np.float32)\n",
    "    \n",
    "    label = io.loadmat('./../'+datasetName+'11x11/TeLabel.mat')\n",
    "    TsLabel = label['Data']\n",
    "\n",
    "    \n",
    "    TrainPatch1 = torch.from_numpy(TrainPatch)\n",
    "#         TrainPatch1 = TrainPatch1.permute(0,3,1,2)\n",
    "    TrainLabel1 = torch.from_numpy(TrLabel)-1\n",
    "    TrainLabel1 = TrainLabel1.long()\n",
    "    \n",
    "\n",
    "    TestPatch1 = torch.from_numpy(TestPatch)\n",
    "#         TestPatch1 = TestPatch1.permute(0,3,1,2)\n",
    "    TestLabel1 = torch.from_numpy(TsLabel)-1\n",
    "    TestLabel1 = TestLabel1.long()\n",
    "\n",
    "    Classes = len(np.unique(TrainLabel1))\n",
    "    print(\"Train data shape = \", TrainPatch1.shape)\n",
    "    print(\"Train label shape = \", TrainLabel1.shape)\n",
    "    print(\"Test data shape = \", TestPatch1.shape)\n",
    "    print(\"Test label shape = \", TestLabel1.shape)\n",
    "    \n",
    "    KAPPA = []\n",
    "    OA = []\n",
    "    AA = []\n",
    "    ELEMENT_ACC = np.zeros((3, Classes))\n",
    "\n",
    "    for iter in range(3):\n",
    "        inputshape = TrainPatch1.shape[1:]\n",
    "        clf = get_model_compiled(inputshape, Classes, w_decay = 0.02)\n",
    "        clf.summary()\n",
    "        valdata = (TestPatch1.cpu().detach().numpy(), keras_to_categorical(TestLabel1.reshape(-1).cpu().detach().numpy(),Classes))\n",
    "        clf.fit(TrainPatch1.cpu().detach().numpy(), keras_to_categorical(TrainLabel1.reshape(-1).cpu().detach().numpy(),Classes),\n",
    "                            batch_size=batchsize,\n",
    "                            epochs=EPOCH,\n",
    "                            verbose=True,\n",
    "                            validation_data=valdata,\n",
    "                            callbacks = [ModelCheckpoint(datasetName+\"/best_model_HSIOnly_Conv3D.h5\", monitor='val_accuracy', verbose=0, save_best_only=True)])\n",
    "\n",
    "\n",
    "\n",
    "        clf = load_model(datasetName+\"/best_model_HSIOnly_Conv3D.h5\")\n",
    "        pred_y = np.argmax(clf.predict(TestPatch1.cpu().detach().numpy()), axis=1)\n",
    "\n",
    "        y_test = TestLabel1.reshape(-1).cpu().detach().numpy()\n",
    "        oa = accuracy_score(y_test, pred_y)*100\n",
    "        confusion = confusion_matrix(y_test, pred_y)\n",
    "        each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "        kappa = cohen_kappa_score(y_test, pred_y)*100\n",
    "        KAPPA.append(kappa)\n",
    "        OA.append(oa)\n",
    "        AA.append(aa)\n",
    "        ELEMENT_ACC[iter, :] = each_acc\n",
    "\n",
    "    print(\"--------\" + datasetName + \" Training Finished-----------\")\n",
    "    record.record_output(OA, AA, KAPPA, ELEMENT_ACC,'./' + datasetName +'/Conv3D_Report_' + datasetName +'.txt')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
